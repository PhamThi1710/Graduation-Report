@misc{sahoo2024systematic,
    title={A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications},
    author={Pranab Sahoo and Ayush Kumar Singh and Sriparna Saha and Vinija Jain and Samrat Mondal and Aman Chadha},
    year={2024},
    eprint={2402.07927},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@misc{ibm_knowledge_graph,
  author = {{IBM}},
  title = {What is a Knowledge Graph?},
  url = {https://www.ibm.com/topics/knowledge-graph},
  note = {Accessed: 2024-09-22}
}

@inproceedings{10.5555/2969239.2969296,
author = {Piech, Chris and Bassen, Jonathan and Huang, Jonathan and Ganguli, Surya and Sahami, Mehran and Guibas, Leonidas and Sohl-Dickstein, Jascha},
title = {Deep knowledge tracing},
year = {2015},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {Knowledge tracing—where a machine models the knowledge of a student as they interact with coursework—is a well established problem in computer supported education. Though effectively modeling student knowledge would have high educational impact, the task has many inherent challenges. In this paper we explore the utility of using Recurrent Neural Networks (RNNs) to model student learning. The RNN family of models have important advantages over previous methods in that they do not require the explicit encoding of human domain knowledge, and can capture more complex representations of student knowledge. Using neural networks results in substantial improvements in prediction performance on a range of knowledge tracing datasets. Moreover the learned model can be used for intelligent curriculum design and allows straightforward interpretation and discovery of structure in student tasks. These results suggest a promising new line of research for knowledge tracing and an exemplary application task for RNNs.},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1},
pages = {505–513},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'15}
}

@article{10.1145/3569576,
author = {Abdelrahman, Ghodai and Wang, Qing and Nunes, Bernardo},
title = {Knowledge Tracing: A Survey},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3569576},
doi = {10.1145/3569576},
abstract = {Humans’ ability to transfer knowledge through teaching is one of the essential aspects for human intelligence. A human teacher can track the knowledge of students to customize the teaching on students’ needs. With the rise of online education platforms, there is a similar need for machines to track the knowledge of students and tailor their learning experience. This is known as the Knowledge Tracing (KT) problem in the literature. Effectively solving the KT problem would unlock the potential of computer-aided education applications such as intelligent tutoring systems, curriculum learning, and learning materials’ recommendation. Moreover, from a more general viewpoint, a student may represent any kind of intelligent agents including both human and artificial agents. Thus, the potential of KT can be extended to any machine teaching application scenarios which seek for customizing the learning experience for a student agent (i.e., a machine learning model). In this paper, we provide a comprehensive survey for the KT literature. We cover a broad range of methods starting from the early attempts to the recent state-of-the-art methods using deep learning, while highlighting the theoretical aspects of models and the characteristics of benchmark datasets. Besides these, we shed light on key modelling differences between closely related methods and summarize them in an easy-to-understand format. Finally, we discuss current research gaps in the KT literature and possible future research and application directions.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {224},
numpages = {37},
keywords = {survey, factor analysis, intelligent education, Bayesian knowledge tracing (BKT), key-value memory, sequence modelling, deep learning, memory networks, Knowledge tracing}
}

@misc{hu2024fokepersonalizedexplainableeducation,
      title={FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering}, 
      author={Silan Hu and Xiaoning Wang},
      year={2024},
      eprint={2405.03734},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2405.03734}, 
}

@article{Raj2022,
  title={An improved adaptive learning path recommendation model driven by real-time learning analytics},
  author={Raj, Navaneeth Santhosh and Renumol, Vijaya Geetha},
  journal={Journal of Computers in Education},
  volume={11},
  pages={121--148},
  year={2022},
  doi={10.1007/s40692-022-00250-y},
  publisher={Springer}
}

@article{li2024explainable,
  title={Explainable Few-shot Knowledge Tracing},
  author={Li, Haoxuan and Yu, Jifan and Ouyang, Yuanxin and Liu, Zhuang and Rong, Wenge and Li, Juanzi and Xiong, Zhang},
  journal={arXiv preprint arXiv:2405.14391},
  year={2024}
}

@article{DBLP:journals/corr/abs-2201-11903,
  author       = {Jason Wei and
                  Xuezhi Wang and
                  Dale Schuurmans and
                  Maarten Bosma and
                  Ed H. Chi and
                  Quoc Le and
                  Denny Zhou},
  title        = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2201.11903},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.11903},
  eprinttype    = {arXiv},
  eprint       = {2201.11903},
  timestamp    = {Fri, 22 Apr 2022 16:06:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-11903.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1812-09628,
  author       = {Ali Alkhatlan and
                  Jugal Kalita},
  title        = {Intelligent Tutoring Systems: {A} Comprehensive Historical Survey
                  with Recent Developments},
  journal      = {CoRR},
  volume       = {abs/1812.09628},
  year         = {2018},
  url          = {http://arxiv.org/abs/1812.09628},
  eprinttype    = {arXiv},
  eprint       = {1812.09628},
  timestamp    = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1812-09628.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{gao2024retrievalaugmentedgenerationlargelanguage,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.10997}, 
}

@misc{lin2024revolutionizingretrievalaugmentedgenerationenhanced,
      title={Revolutionizing Retrieval-Augmented Generation with Enhanced PDF Structure Recognition}, 
      author={Demiao Lin},
      year={2024},
      eprint={2401.12599},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2401.12599}, 
}

@misc{ng2024educationalpersonalizedlearningpath,
      title={Educational Personalized Learning Path Planning with Large Language Models}, 
      author={Chee Ng and Yuen Fung},
      year={2024},
      eprint={2407.11773},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.11773}, 
}

@inproceedings{10.1145/3626252.3630938,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630938},
doi = {10.1145/3626252.3630938},
abstract = {In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {750–756},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{Frankford_2024, series={ICSE-SEET ’24},
   title={AI-Tutoring in Software Engineering Education},
   url={http://dx.doi.org/10.1145/3639474.3640061},
   DOI={10.1145/3639474.3640061},
   booktitle={Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
   publisher={ACM},
   author={Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth},
   year={2024},
   month=apr, pages={309–319},
   collection={ICSE-SEET ’24} }


@article{cross_modal_2021,
title = {Cross Modal, Cross Cultural, Cross Lingual, Cross Domain, and Cross Site Global OER Network},
author = {Sahan Bulathwela and Maria Perez-Ortiz and E. S. V. Ranawaka and R. I. P. B. B. Siriwardana and G. A. K. Y. Ganepola and Thiruparan Ravikkumar and Shenal Pussegoda and Erik Novak and Emine Yilmaz and John Shawe-Taylor},
year = {2021}
}

@misc{geeksforgeeks2024,
  author = {GeeksforGeeks},
  title = {React vs Angular vs Vue: Which Framework is the Best?},
  year = {2024},
  url = {https://www.geeksforgeeks.org/react-vs-angular-vs-vue-which-framework-is-the-best/},
  note = {Accessed: 2024-12-12}
}

@misc{hackernoon2024,
  author = {HackerNoon},
  title = {Python Web Frameworks Compared: Django vs FastAPI},
  year = {2024},
  url = {https://hackernoon.com/python-web-frameworks-compared-django-vs-fastapi#:~:text=Python%20Web%20Frameworks%20Compared%3A%20Django%20vs%20FastAPI%201,...%208%20Community%20and%20Support%20...%20More%20items},
  note = {Accessed: 2024-12-12}
}

@misc{dbengines2024,
  author = {DB-Engines},
  title = {ArangoDB vs Neo4j vs OrientDB},
  year = {2024},
  url = {https://db-engines.com/en/system/ArangoDB%3bNeo4j%3bOrientDB},
  note = {Accessed: 2024-12-12}
}

@misc{liu2023gevalnlgevaluationusing,
      title={G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment}, 
      author={Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu},
      year={2023},
      eprint={2303.16634},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.16634}, 
}

@inproceedings{zhang2020new,
  author    = {Zhao Zhang and Armelle Brun and Anne Boyer},
  title     = {New Measures for Offline Evaluation of Learning Path Recommenders},
  booktitle = {15th European Conference on Technology Enhanced Learning (EC-TEL 2020)},
  year      = {2020},
  month     = sep,
  address   = {Heidelberg, Germany},
  doi       = {10.1007/978-3-030-57717-9_19},
  url       = {https://hal.archives-ouvertes.fr/hal-02974676},
  publisher = {Springer},
}

@misc{li2025preferenceleakagecontaminationproblem,
      title={Preference Leakage: A Contamination Problem in LLM-as-a-judge}, 
      author={Dawei Li and Renliang Sun and Yue Huang and Ming Zhong and Bohan Jiang and Jiawei Han and Xiangliang Zhang and Wei Wang and Huan Liu},
      year={2025},
      eprint={2502.01534},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.01534}, 
}

@online{openaiPromptCaching,
  author       = {{OpenAI}},
  title        = {Prompt Caching Guide},
  year         = {2024},
  url          = {https://platform.openai.com/docs/guides/prompt-caching},
  urldate      = {2025-05-04},
  note         = {Accessed May 4, 2025}
}
